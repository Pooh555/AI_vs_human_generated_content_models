{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Human Faces From Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "from supervision import Detections\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2309021931.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    image_path = \"/home/pooh/Downloads/0e4243e0-9fdc-11ef-8edd-1d0dc01e4477.webp\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/pooh/Downloads/IMG_20250418_233052.jpg\"\n",
    "original_image_bgr = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully: /home/pooh/Downloads/ai-generated-professional-portrait-1170x686.jpeg\n",
      "\n",
      "0: 384x640 1 FACE, 34.0ms\n",
      "Speed: 1.3ms preprocess, 34.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Found 1 face(s). Cropping and saving...\n",
      "Saved cropped face 0 to: cropped_faces/ai-generated-professional-portrait-1170x686_face_0.jpg\n"
     ]
    }
   ],
   "source": [
    "if original_image_bgr is None:\n",
    "    print(f\"Error: Could not load image from path: {image_path}\")\n",
    "    # Handle the error appropriately, e.g., exit or raise an exception\n",
    "    exit() # Exit the script if image loading fails\n",
    "else:\n",
    "    print(f\"Image loaded successfully: {image_path}\")\n",
    "\n",
    "    # --- Perform inference ---\n",
    "    # It's often efficient to pass the loaded image array directly\n",
    "    output: list[Results] = model(original_image_bgr) # Pass the BGR image array\n",
    "    results_ultralytics: Results = output[0] # Get results for the first (only) image\n",
    "\n",
    "    # --- Get bounding boxes ---\n",
    "    # Access the bounding boxes (xyxy format) from the results\n",
    "    # .cpu() moves tensor to CPU, .numpy() converts to NumPy array\n",
    "    bboxes_xyxy = results_ultralytics.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    # Define the directory to save cropped faces\n",
    "    output_crop_dir = \"cropped_faces\"\n",
    "    os.makedirs(output_crop_dir, exist_ok=True) # Create directory if it doesn't exist\n",
    "\n",
    "    # Define a base name for the output files\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    print(f\"Found {len(bboxes_xyxy)} face(s). Cropping and saving...\")\n",
    "\n",
    "    # --- Iterate through detected faces and crop ---\n",
    "    if len(bboxes_xyxy) > 0:\n",
    "        for i, bbox in enumerate(bboxes_xyxy):\n",
    "            # Extract integer coordinates (xmin, ymin, xmax, ymax)\n",
    "            x_min, y_min, x_max, y_max = map(int, bbox[:4])\n",
    "\n",
    "            # Add padding or ensure coordinates are within bounds if necessary (optional)\n",
    "            # Example: Adding 10px padding, ensuring it stays within image limits\n",
    "            padding = 0 # Set padding pixels if desired\n",
    "            h, w = original_image_bgr.shape[:2]\n",
    "            x_min = max(0, x_min - padding)\n",
    "            y_min = max(0, y_min - padding)\n",
    "            x_max = min(w, x_max + padding)\n",
    "            y_max = min(h, y_max + padding)\n",
    "\n",
    "            # Crop the face region from the original BGR image using NumPy slicing\n",
    "            cropped_face_bgr = original_image_bgr[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            # --- Save the cropped face ---\n",
    "            # Check if the crop is valid (has width and height)\n",
    "            if cropped_face_bgr.shape[0] > 0 and cropped_face_bgr.shape[1] > 0:\n",
    "                # Convert the cropped BGR face to RGB for saving with PIL\n",
    "                cropped_face_rgb = cv2.cvtColor(cropped_face_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Convert the NumPy array (RGB) to a PIL Image object\n",
    "                cropped_face_pil = Image.fromarray(cropped_face_rgb)\n",
    "\n",
    "                # Define the output path for this specific cropped face\n",
    "                output_crop_path = os.path.join(output_crop_dir, f\"{base_filename}_face_{i}.jpg\")\n",
    "\n",
    "                # Save the cropped face image\n",
    "                cropped_face_pil.save(output_crop_path)\n",
    "                print(f\"Saved cropped face {i} to: {output_crop_path}\")\n",
    "            else:\n",
    "                print(f\"Warning: Skipped saving face {i} due to invalid dimensions after cropping.\")\n",
    "    else:\n",
    "        print(\"No faces were detected in the image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
